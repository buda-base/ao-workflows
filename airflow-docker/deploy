#!/usr/bin/env bash
#
#
# Create a deployment directory for the airflow docker compose service

#

set -e
export ME=$(basename $0)
. ~/bin/init_sys.sh

#region CONST
# Allows RW access to RS Archives
# prod:
# Prod userid should be `service` uid on bodhi & sattva
_PROD_SYNC_ACCESS_UID=1001
# Standard user under docker
_DEV_SYNC_ACCESS_UID=5000

# See bdrc-docker-compose.yml - leaving this unset is handled with the:
# - ${ARCH_ROOT:-/mnt}:/mnt
# stanza in volumes: This has the same meaning as in bash variable substitution

_PROD_ARCH_ROOT=
_DEV_ARCH_ROOT=.

#MY_SYNC_ACCESS_UID=${_PROD_SYNC_ACCESS_UID}
#MY_ARCH_ROOT=${_PROD_ARCH_ROOT}

MY_SYNC_ACCESS_UID=${_DEV_SYNC_ACCESS_UID}
MY_ARCH_ROOT=${_DEV_ARCH_ROOT}

#endregion
function usage() {
  echo "Usage: ${ME} [-h|--help] -s|--source <source-dir> -d|--dest <deploy-dir> [-i|--init-env <deploy-dir>]"
  echo "Create and deployment directory for the airflow docker compose service"
  echo "  -h|--help"
  echo "  -s|--source <source-dir>: source directory"
  echo "  -d|--dest <deploy-dir>: deployment directory"
  echo "  -i|--init-env <deploy-dir>: initialize test environment AFTER creating it with --s and --d"
  echo ""
  echo "the -i|--init-env is used standalone to build a local copy of the RS archive for testing."
  echo "You need to manually reference its output in the bdrc-docker-compose.yaml scheduler:volumes:"
}
init_test_env() {

  # Make archive roots
  for d in $(seq 0 99); do
    todo=${1}/Archive$(($d / 25))/$(printf "%02d" $d)
    mkdir -p $todo || exit 1
    chmod -R 777 $todo
  done

  # Set up the work directory that the production environment needs
  # Make download target
  todo="${1}/AO-staging-Incoming/bag-download"
  mkdir -p $todo || exit 1
  chmod -R 777 "${1}/AO-staging-Incoming"

}

OPTIONS=$(getopt -o hs:d:i: --long help,source,dest,init-env -- "$@")

while true; do # Parse command line options
  case "$1" in
  -s | --source)
    export SRC=${2?"No source directory given."}
    shift 2
    ;;
  -d | --dest)
    export DEPLOY=${2?"No deployment directory given."}
    shift 2
    ;;
  -i | --init-env)
    init_home=${2?"No archival parent directory given."}
    init_test_env $2
    exit $?
    ;;
  -h | --help)
    usage
    exit 1
    ;;

  --)
    shift
    break
    ;;
  *)
    break
    ;;
  esac
done

if [[ -z $SRC ]] || [[ -z $DEPLOY ]]; then
  echo no args. bye
  exit 1
fi

[[ ! -d $DEPLOY ]] && {   mkdir $DEPLOY || exit 1 ;  }
  # jimk aow-14 - add sync logs
for DD in "$DEPLOY/dags" "$DEPLOY/logs"  "$DEPLOY/plugins" "$DEPLOY/processing" "$DEPLOY/processing/logs" ; do
    mkdir -p $DD
    chmod 777 $DD
done


log_echo docker-compose
cp -p $SRC/bdrc-docker-compose.yml $DEPLOY/docker-compose.yaml
log_echo dags
cp -rp $SRC/dags ${DEPLOY}

# Borrowed from bdrc-docker.sh
export SECRETS=$DEPLOY/.docker-secrets
mkdir -p "${SECRETS}"
log_echo secrets - bdrc
cp -vp ~/.config/bdrc/docker/* "${SECRETS}" || exit 1
#
# These section names, 'default' and 'ap_northeast', are hard-coded in the dags/..py
log_echo aws default
./extract-section.pl ~/.aws/credentials default > ${SECRETS}/aws-credentials || exit 1
# jimk archive-ops-14 - support other regions
log_echo aws-others
./extract-section.pl ~/.aws/credentials ap_northeast >> ${SECRETS}/aws-credentials || exit 1
# chmod u-w "${SECRETS}"

log_echo .env
cat <<EOF >$DEPLOY/.env
SECRETS=.docker-secrets
# hush run-time warnings of build environments
COMPOSE_PY_REQS=
BIN=
COMPOSE_BUILD_DIR=
# Comment ARCH_ROOT in production, to use the default /mnt in bdrc-docker-compose
ARCH_ROOT=${MY_ARCH_ROOT}
#
# For build only
BUILD_CONFIG_ROOT=

SYNC_ACCESS_UID=$MY_SYNC_ACCESS_UID
EOF

# They say this is a BUILD image arg, not a runtime arg
# AIRFLOW_UID=1000 # j...
# AIRFLOW_GID=0

log_echo "Deployment directory created: $DEPLOY"
log_echo "manage  the services with: cd $DEPLOY && docker compose [up -d | down | log | exec....."
